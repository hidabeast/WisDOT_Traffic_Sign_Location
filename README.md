-	TO USE: You must download the Depth-Anything-V2-Large pre-trained model, create a new folder called 'checkpoints', put that file in the checkpoints folder, and then
-	put that folder inside the Depth-AnythingV2 folder. This will enable Depth-Anything to use the model when creating the depth maps.

-	MY FINAL PRODUCT:
-	I have made two .py files: dist_estimation.py and main.py.
-	dist_esimation.py comprises one function: calculate_distance(). This function needs to take in an image path, the location of the signs in the picture, and the distance from the camera to the gps mount(both z and y). 
-	How it works: it first generates a depth map for the given image, and then it uses the known y coordinates and distances to generate an exponential model to fit the relation. It is very important to note that since the distances given are from the GPS MOUNT to the pavement, I did some simple trigonometry to get instead the distances from the CAMERA to the pavement. Using this model, we calculate the distance to the sign using the gray value of the sign. I also create a fit plot for the exponential model – this is not strictly necessary but good for testing. 
-	It is VERY IMPORTANT to note that 1: calculate_distance() assumes an array of size one for the location of the sign. This will have to be changed to work for multiple signs in one picture. And 2: for testing purposes, I have commented out the code that generates a depth map for the picture and am using pre-generated pictures. If you want to change it back to generating a new map for each picture, you will have to uncomment this and comment out the code that uses the pregenerated depth maps. 
-	main.py comprises some basic code and one function: calculate_position(). calculate_position() needs to take the image paths, the image data(2D array containing lat, long, alt, yaw, pitch, roll), the horizontal angle of vision(fixed), the vertical angle of vision(fixed), the distance from the camera to the gps mount in Y(fixed), the distance from the camera to the gps mount in Z(fixed), and a 2D array containing the locations of signs in each picture. 
-	Here’s how it works: first, we call calculate_distance() for each picture and store the results in ‘distances.’ Then, for each item in ‘distances,’ we calculate the horizontal and vertical angles to the sign(assuming there is one) using a linear scale for angle and pixel coordinate. Using the angles, we then calculate the x, y, and z relative to the CAMERA for the sign using basic trigonometry (Remember that before we calculated the distance relative to the CAMERA, not the GPS. This is why!). Then, since the gps is directly behind the camera, I add the distances from VEHICLE_DELTA_Y and VEHICLE_DELTA_Z to the results to get the position relative to the gps. However, we are not done. These positions mean nothing without a relation to the earth. Now, using the yaw/pitch/roll, I compute the rotation matrices for each and multiply them together to achieve the overall rotation matrix. Finally, I apply the rotation matrix to the position we found relative to the gps to get the position still relative to the gps, but with North being in the positive y direction and compensation for pitch and yaw. 
-	Important notes on calculate_position() :
•	Right now it assumes there is only one sign for image – you will need to change this later
•	I have not fully tested the results – the only thing I have tested are that the rotation matrices are correct. I have no idea if the distance for calculate_distance() are even correct. You will have to go step by step and test everything to make sure that nothing is going wrong and we are doing the right thing.
•	The coordinate system is weird: y is forward and backward, x is left and right, and z is up and down. Because of this, the rotation matrices are not multiplied in the conventional way. 
-	Let me clarify what the final results mean: the result of running main.py is a 2D array with the position of the sign relative to the gps in feet in each picture. Remember that x=0 means we are pointing North.
-	![picture of x, y, z drawing](crude_diagram.png)
-	For example, in the picture, we have the van/gps position, and the resulting x, y, z of the sign relative to the gps. Notice that we don’t care about which way the van is heading in! We have already compensated for that using the rotation matrices. So, as you can see, the positive y displacement indicates y feet North, the positive x displacement indicates x feet East, and the positive z displacement indicates z feet Up. I hope that clarifies things. 
-	What will need to be done in the future concerning these two files:
•	As I have already said, making calculate_distance() and calculate_position() compatible for multiple signs in each image.
•	Automatic sign detection.
•	Final interpretation of the coordinates. Since we have the x, y, and z of a sign relative to each gps coordinate in feet, you will need to figure out what coordinate system you want to use to find the final position of the sign on the earth, since the positions of the van are in lat/long and are not necessarily compatible with feet and a cartesian coordinate system. 
•	Testing these two functions to make sure they output the correct results. You will have to get the yaw/pitch/roll information from Andy. 

-	Final notes: please please PLEASE reach out to me if you have ANY questions whatsoever. I am more than happy to answer questions and clarify anything. You can email me at johndrathgeber@gmail.com at any time and I will usually respond within the day. 
-	As I’m sure you know, ChatGPT and other AI models are largely unreliable. I tried to use them minimally when creating these two files(mostly because I actually know what’s going on here mathematically) – in fact, I only used ChatGPT for a couple things in dist_estimation.py and main.py is written completely by hand. If you are running into issues, I recommend you reach out to me instead of asking ChatGPT because ChatGPT will probably do something wrong because we are using an unconventional coordinate system. I will be more than happy to help. 
